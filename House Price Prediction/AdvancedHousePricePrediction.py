# -*- coding: utf-8 -*-
"""ML.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SyMUqZgD_UK-JX52Z5ObeKnbn3hHD41s

## **Advance House Price Prediction: EDA**
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns

pd.pandas.set_option('display.max_columns',None) #Display all data of dataframe

dataset=pd.read_csv('train.csv')
print(dataset.shape)

dataset.head()

"""Missing Value"""

features_with_na=[features for features in dataset.columns if dataset[features].isnull().sum()>1]

for features in features_with_na:
    print(features,np.round(dataset[features].isnull().mean(),4),'% missing values')

# Since there are many missing values, we will need to find relationship b/w missing values and sales price
for features in features_with_na:
  data=dataset.copy()
  data[features]=np.where(data[features].isnull(),1,0) # 1 if observation was missing or zero
  data.groupby(features)['SalePrice'].median().plot.bar() # mean saleprice where info is missing and present
  plt.title(features+' missing value vs median price')
  plt.show()

print("Id of houses {}".format(len(dataset.Id)))

"""Numerical Variables"""

numerical_features=[feature for feature in dataset.columns if dataset[feature].dtypes != 'O'] # List of numerical variables
# O stands for object dtype
print("No. of numerical variable: ",len(numerical_features))
dataset[numerical_features].head() # visualise numerical variables

"""Temporal Variables(Eg. datetime variable)

"""

# list of variable that contain year info
year_feature=[feature for feature in numerical_features if 'Yr' in feature or 'Year' in feature]
year_feature

for feature in year_feature:
  print(feature,dataset[feature].unique())

dataset.groupby('YrSold')['SalePrice'].median().plot()
plt.xlabel('Year sold')
plt.ylabel('Median House Price')
plt.title('House Price vs Year sold')

# Compare the difference between All years feature and SalePrice
for feature in year_feature:
  if feature!='YrSold':
    data=dataset.copy()
    data[feature]=data['YrSold']-data[feature]
    plt.scatter(data[feature],data['SalePrice'])
    plt.xlabel(feature)
    plt.ylabel('SalePrice')
    plt.show()

discrete_feature=[feature for feature in numerical_features if len(dataset[feature].unique())<25 and feature not in year_feature+['Id']]
print("Discrete variables count: {}".format(len(discrete_feature)))
discrete_feature

dataset[discrete_feature].head()

# Relationship b/w discrete feature and SalePrice
for feature in discrete_feature:
  data=dataset.copy()
  data.groupby(feature)['SalePrice'].median().plot.bar()
  plt.xlabel(feature)
  plt.ylabel('SalePrice')
  plt.title(feature)
  plt.show()

"""Continous Variable"""

continous_feature=[feature for feature in numerical_features if feature not in discrete_feature+year_feature+['Id']]
print("Continous variable count: {}".format(len(continous_feature)))

for feature in continous_feature:
  data=dataset.copy()
  data[feature].hist(bins=25)
  plt.xlabel(feature)
  plt.ylabel("Count")
  plt.title(feature)
  plt.show()

# Lograthmic transformation
for feature in continous_feature:
  data=dataset.copy()
  if 0 in data[feature].unique():
    pass
  else:
    data[feature]=np.log(data[feature])
    data['SalePrice']=np.log(data['SalePrice'])
    plt.scatter(data[feature],data['SalePrice'])
    plt.xlabel('feature')
    plt.ylabel('SalesPrice')
    plt.title(feature)
    plt.show()

"""Outlier

"""

for feature in continous_feature:
  data=dataset.copy()
  if 0 in data[feature].unique():
    pass
  else:
    data[feature]=np.log(data[feature])
    data.boxplot(column=feature) # only for continous variable, not for categorical feature
    plt.xlabel(feature)
    plt.ylabel("SalesPrice")
    plt.title(feature)
    plt.show()

"""Categorical Feature"""

categorical_feature=[feature for feature in dataset.columns if dataset[feature].dtypes=='O']
categorical_feature

dataset[categorical_feature].head()

for feature in categorical_feature:
  print('The feature is {} and no. of categories are {}'.format(feature,len(dataset[feature].unique())))

# Relationship b/w categorical variable and dependent feature
for feature in categorical_feature:
  data=dataset.copy()
  data.groupby(feature)['SalePrice'].median().plot.bar()
  plt.xlabel(feature)
  plt.ylabel('SalePrice')
  plt.show()

"""**Feature Engineering**"""

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(dataset.drop(['SalePrice'],axis=1),dataset['SalePrice'],test_size=0.1,random_state=0)

X_train.shape,X_test.shape

features_nan=[feature for feature in dataset.columns if dataset[feature].isnull().sum()>1 and dataset[feature].dtypes=='O']
for feature in features_nan:
  print("{}: {}% missing values".format(feature,np.round(dataset[feature].isnull().mean(),4)))

# replacing missing value with new label
def replace_cat_feature(dataset,features_nan):
  data=dataset.copy()
  data[features_nan]=data[features_nan].fillna('Missing')
  return data
dataset=replace_cat_feature(dataset,features_nan)
dataset[features_nan].isnull().sum()

dataset.head()

# numerical variable that contains missing value
numerical_with_nan=[feature for feature in dataset.columns if dataset[feature].isnull().sum()>1 and dataset[feature].dtypes!='O']
for feature in numerical_with_nan:
  print("{}: {}% missing value".format(feature,np.around(dataset[feature].isnull().mean(),4)))

# replacing numerical missing value
for feature in numerical_with_nan:
  median_value=dataset[feature].median() # replacing by median, since there are lots of outliers

  #creating new feature to capture nan value
  dataset[feature+'nan']=np.where(dataset[feature].isnull(),1,0)
  dataset[feature].fillna(median_value,inplace=True)
dataset[numerical_with_nan].isnull().sum()

dataset.head(50)

for feature in ['YearBuilt','YearRemodAdd','GarageYrBlt']:
  dataset[feature]=dataset['YrSold']-dataset[feature]

dataset.head()

dataset[['YearBuilt','YearRemodAdd','GarageYrBlt']].head()

num_features=['LotFrontage','LotArea','1stFlrSF','GrLivArea','SalePrice']
for feature in num_features:
  dataset[feature]=np.log(dataset[feature])

dataset.head()

# Rare categorical feature: feature that are present <1% of observation
for feature in categorical_feature:
  temp=dataset.groupby(feature)['SalePrice'].count()/len(dataset)
  temp_df=temp[temp>0.01].index
  dataset[feature]=np.where(dataset[feature].isin(temp_df),dataset[feature],'RareVar')

dataset.head(100)

"""Feature Scaling"""

features_scale=[feature for feature in dataset.columns if feature not in ['Id','SalePrice'] and dataset[feature].dtype!='O']

from sklearn.preprocessing import MinMaxScaler
scaler=MinMaxScaler()
scaler.fit(dataset[features_scale])

data=pd.concat([dataset[['Id', 'SalePrice']].reset_index(drop=True),
                  pd.DataFrame(scaler.transform(dataset[features_scale]),columns=features_scale)],axis=1)

data.head()

data.to_csv('X_train.csv',index=False)

"""**Feature Selection**"""

dataset=pd.read_csv('X_train.csv')
dataset.head()

from sklearn.linear_model import Lasso
from sklearn.feature_selection import SelectFromModel
dataset=pd.read_csv('X_train.csv')
dataset.head()

y_train=dataset[['SalePrice']]
X_train=dataset.drop(['Id','SalePrice'],axis=1)

feature_sel_model=SelectFromModel(Lasso(alpha=0.005,random_state=0))
feature_sel_model.fit(X_train,y_train)

feature_sel_model.get_support()

seleted_feat=X_train.columns[(feature_sel_model.get_support())]
print('Total features: {}'.format((X_train.shape[1])))
print('Selected features: {}'.format(len(seleted_feat)))
print('Features with coeffecient shrank to zero:{}'.format(np.sum(feature_sel_model.estimator_.coef_==0)))

seleted_feat

X_train=X_train[seleted_feat]
X_train.head()